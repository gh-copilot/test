name: CI

on:
  push:
    branches: [ test ]

#   schedule:
#     - cron: '0 12 * * *'
  
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

defaults:
  run:
    shell: bash

env:
  FORCE_COLOR : 'true' # Force colors in console output
  CI: 'true'
  TERM: 'xterm-256color'
  TESTSET: 'arab_filtered' # 'arab' or 'arab_filtered' or'ytfaces'
  TESTSET_TYPE: '' # or '_single' or '_double' or '' (single or double used for arab only)

jobs:
  prepare_arab_dataset:
    runs-on: ubuntu-latest
    
    steps:
      - name: Download Arab dataset
        if: ${{ env.TESTSET == 'arab' }}
        uses: robinraju/release-downloader@v1.3
        with:
          repository: "${{ github.repository }}"
          tag: "testset${{ env.TESTSET_TYPE }}_numpy_v1.0"
          fileName: "*"
          tarBall: false
          zipBall: false
          out-file-path: "testset"
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Extract Arab dataset
        if: ${{ env.TESTSET == 'arab' }}
        run: |
          cd testset
          rm -v testset_complete.7z || echo ""
          
          for file in *.7z; do
            7z x "$file"
            rm "$file"
          done
      
      - name: Compress whole Arab dataset
        if: ${{ env.TESTSET == 'arab' }}
        run: 7z a testset_complete.7z testset

      - name: Release Files
        if: ${{ env.TESTSET == 'arab' }}
        uses: softprops/action-gh-release@v1
        with:
          tag_name: "testset${{ env.TESTSET_TYPE }}_numpy_v1.0"
          name: "Testset Numpy"
          files: "testset_complete.7z"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  Test:
    needs: [prepare_arab_dataset]
    runs-on: ubuntu-latest
    name: "${{ matrix.model }}, CS=${{ matrix.conflict_solver }}"
    strategy:
      fail-fast: false
      matrix:
        model: 
          # Normalization N = 50
          - 'affectnet_n=50_minmax.model'
#           - 'celebreties_n=50_minmax.model'
#           - 'fairface_n=50_minmax.model'
#           - 'FEI_frontal_n=50_minmax.model'
#           - 'FEI_n=50_minmax.model'
#           - 'ffhq_n=50_minmax.model'
#           - 'icml_face_data_n=50_minmax.model'
#           - 'mug_0.1+FACES+Yale-FacesB+JAFFE+TFEID+FEI_frontal_n=50_minmax.model'
          - 'mug_0.3+FACES+Yale-FacesB+JAFFE+TFEID+FEI_frontal_n=50_minmax.model'
#           - 'mug_0.3+FACES+Yale-FacesB_n=50_minmax.model'
#           - 'mug_0.5+FACES+Yale-FacesB+JAFFE+TFEID+FEI_frontal_n=50_minmax.model'
#           - 'mug_0.5+FACES+Yale-FacesB_n=50_minmax.model'
#           - 'mug_0.8+FACES+Yale-FacesB+JAFFE+TFEID+FEI_frontal_n=50_minmax.model'
#           - 'mug_0.8+FACES+Yale-FacesB_n=50_minmax.model'
#           - 'mug_1.0+FACES+Yale-FacesB+JAFFE+TFEID+FEI_frontal_n=50_minmax.model'
#           - 'mug_1.0+FACES+Yale-FacesB_n=50_minmax.model'
#           - 'FACES_n=50_minmax.model'
#           - 'FACES_n=50_std.model'
#           - 'mug_0.1+FACES+Yale-FacesB_n=50_minmax.model'
#           - 'mug_0.1+FACES+Yale-FacesB_n=50_std.model'
#           - 'mug_1.0_n=50_minmax.model'
#           - 'mug_1.0_n=50_std.model'
#           - 'Yale-FacesB_n=50_minmax.model'
#           - 'Yale-FacesB_n=50_std.model'
          
#           # PCA(whiten=True) N = 50
#           - 'FACES_n=50_minmax_whiten.model'
#           - 'FACES_n=50_std_whiten.model'
#           - 'FACES_n=50_whiten.model'
#           - 'mug_0.1+FACES+Yale-FacesB_n=50_minmax_whiten.model'
#           - 'mug_0.1+FACES+Yale-FacesB_n=50_std_whiten.model'
#           - 'mug_0.1+FACES+Yale-FacesB_n=50_whiten.model'
#           - 'mug_1.0_n=50_minmax_whiten.model'
#           - 'mug_1.0_n=50_std_whiten.model'
#           - 'mug_1.0_n=50_whiten.model'
#           - 'Yale-FacesB_n=50_minmax_whiten.model'
#           - 'Yale-FacesB_n=50_std_whiten.model'
#           - 'Yale-FacesB_n=50_whiten.model'


#           # Hybrid N = 20
#           - 'mug_0.1+FACES+FEI_frontal+JAFFE+Yale-FacesB_n=20.model'
#           - 'mug_0.1+FACES+Yale-FacesB_n=20.model'
#           - 'mug_0.3+FACES+FEI_frontal+JAFFE+Yale-FacesB_n=20.model'
#           - 'mug_0.3+FACES+Yale-FacesB_n=20.model'
#           - 'mug_0.5+FACES+FEI_frontal+JAFFE+Yale-FacesB_n=20.model'
#           - 'mug_0.5+FACES+Yale-FacesB_n=20.model'
#           - 'mug_0.8+FACES+FEI_frontal+JAFFE+Yale-FacesB_n=20.model'
#           - 'mug_0.8+FACES+Yale-FacesB_n=20.model'
#           - 'mug_1.0+FACES+FEI_frontal+JAFFE+Yale-FacesB_n=20.model'
#           - 'mug_1.0+FACES+Yale-FacesB_n=20.model'
#           - 'FACES+FEI_frontal+JAFFE+TFEID+Yale-FacesB_n=20.model'
#           - 'FACES+FEI_frontal+Yale-FacesB_n=20.model'
#           - 'FACES+Yale-FacesB_n=20.model'
#           - 'FEI_frontal+Yale-FacesB_n=20.model'

          
#           # Hybrid N = 30
#           - 'mug_0.1+FACES+FEI_frontal+JAFFE+Yale-FacesB_n=30.model'
#           - 'mug_0.1+FACES+Yale-FacesB_n=30.model'
#           - 'mug_0.3+FACES+FEI_frontal+JAFFE+Yale-FacesB_n=30.model'
#           - 'mug_0.3+FACES+Yale-FacesB_n=30.model'
#           - 'mug_0.5+FACES+FEI_frontal+JAFFE+Yale-FacesB_n=30.model'
#           - 'mug_0.5+FACES+Yale-FacesB_n=30.model'
#           - 'mug_0.8+FACES+FEI_frontal+JAFFE+Yale-FacesB_n=30.model'
#           - 'mug_0.8+FACES+Yale-FacesB_n=30.model'
#           - 'mug_1.0+FACES+FEI_frontal+JAFFE+Yale-FacesB_n=30.model'
#           - 'mug_1.0+FACES+Yale-FacesB_n=30.model'
#           - 'FACES+FEI_frontal+JAFFE+TFEID+Yale-FacesB_n=30.model'
#           - 'FACES+FEI_frontal+Yale-FacesB_n=30.model'
#           - 'FACES+Yale-FacesB_n=30.model'
#           - 'FEI_frontal+Yale-FacesB_n=30.model'

#           # Hybrid N = 50
#           - 'mug_0.1+FACES+FEI_frontal+JAFFE+Yale-FacesB_n=50.model'
#           - 'mug_0.1+FACES+Yale-FacesB_n=50.model'
#           - 'mug_0.3+FACES+FEI_frontal+JAFFE+Yale-FacesB_n=50.model'
#           - 'mug_0.3+FACES+Yale-FacesB_n=50.model'
#           - 'mug_0.5+FACES+FEI_frontal+JAFFE+Yale-FacesB_n=50.model'
#           - 'mug_0.5+FACES+Yale-FacesB_n=50.model'
#           - 'mug_0.8+FACES+FEI_frontal+JAFFE+Yale-FacesB_n=50.model'
#           - 'mug_0.8+FACES+Yale-FacesB_n=50.model'
#           - 'mug_1.0+FACES+FEI_frontal+JAFFE+Yale-FacesB_n=50.model'
#           - 'mug_1.0+FACES+Yale-FacesB_n=50.model'
#           - 'FACES+FEI_frontal+JAFFE+TFEID+Yale-FacesB_n=50.model'
#           - 'FACES+FEI_frontal+Yale-FacesB_n=50.model'
#           - 'FACES+Yale-FacesB_n=50.model'
#           - 'FEI_frontal+Yale-FacesB_n=50.model'

#           # N = 50
#           - 'FACES_48x48_n=50.model'
#           - 'FEI_48x48_n=50.model'
#           - 'FEI_frontal_48x48_n=50.model'
#           - 'mug_48x48_n=50.model'
#           - 'pca_n=50_affectnet.sav'
#           - 'pca_n=50_celebreties.sav'
#           - 'pca_n=50_fairface.sav'
#           - 'pca_n=50_ffhq.sav'
#           - 'pca_n=50_yaleB.sav'
          
#           # N = 100
#           - 'FACES_48x48_n=100.model'
#           - 'FEI_48x48_n=100.model'
#           - 'FEI_frontal_48x48_n=100.model'
#           - 'mug_48x48_n=100.model'
#           - 'pca_n=100_affectnet.sav'
#           - 'pca_n=100_celebreties.sav'
#           - 'pca_n=100_fairface.sav'
#           - 'pca_n=100_ffhq.sav'
#           - 'pca_n=100_yaleB.sav'
          
#           - 'pca_n=200_yaleB.sav'
#           - 'pca_n=400_yaleB.sav'
        
        faces:
          - "2 3 4 5"
          - "6 7"
          - "8"
          - "9"
          - "10"
          - "11"
          - "12"
          - "13 14"
          - "15 16"
          - "17 18"
          - "19 20"
          
        conflict_solver:
          - "true"
          - "false"


    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Add conda to system path
        run: |
          # $CONDA is an environment variable pointing to the root of the miniconda directory
          echo $CONDA/bin >> $GITHUB_PATH
      
      - run: conda update -n base -c defaults conda
      - run: conda install -c conda-forge dlib opencv numpy scikit-learn ipython -y
      - run: conda list
      
      - run: tar -xvf models.tar.xz --skip-old-files
      
      - name: Extract ytfaces dataset
        if: ${{ env.TESTSET == 'ytfaces' }}
        run: |
          tar -xf ytfaces_test_numpy.tar.xz --skip-old-files
          mv ytfaces_test_numpy testset

      - name: Download Arab dataset
        if: ${{ env.TESTSET == 'arab' }}
        uses: robinraju/release-downloader@v1.3
        with:
          repository: "${{ github.repository }}"
          tag: "testset${{ env.TESTSET_TYPE }}_numpy_v1.0"
          fileName: "testset_complete.7z"
          tarBall: false
          zipBall: false
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract arab dataset
        if: ${{ env.TESTSET == 'arab' }}
        run: 7z x testset_complete.7z


      - name: Extract arab filtered dataset
        if: ${{ env.TESTSET == 'arab_filtered' }}
        run: tar -xf arab_double_filtered_testset.tar.xz --skip-old-files
        
      - name: List testset files
        run: ls -lRh testset
        continue-on-error: true
        if: always()

      - name: "Run With Conflict Solver"
        if: ${{ matrix.conflict_solver == 'true' }}
        continue-on-error: true
        run: |
          echo "Conflict Resolution: True"
          echo ""

          IFS=', ' read -r -a faces <<< "${{ matrix.faces }}"
          model_name=$(echo "${{ matrix.model }}" | rev | cut -f 2- -d '.' | rev)
          
          for face in "${faces[@]}" ; do

            python3 -u test_accuracy.py "$PWD/testset" --load-numpy -n "$face" -c --model ${{ matrix.model }} -k 3 5 | tee -a "${model_name}_face=${face}_result_with_conflict_solver.txt"
            
            echo ""
            echo ""
          done
      
      - name: "Run Without Conflict Solver"
        if: ${{ matrix.conflict_solver == 'false' }}
        continue-on-error: true
        run: |
          echo "Conflict Resolution: False"
          echo ""
          IFS=', ' read -r -a faces <<< "${{ matrix.faces }}"
          model_name=$(echo "${{ matrix.model }}" | rev | cut -f 2- -d '.' | rev)
          
          for face in "${faces[@]}" ; do

            python3 -u test_accuracy.py "$PWD/testset" --load-numpy -n "$face" --model ${{ matrix.model }} -k 3 5 | tee -a "${model_name}_face=${face}_result.txt"
            
            echo ""
            echo ""
          done

      - run: ls -lh
        continue-on-error: true
        if: always()
      
      - name: Release Files
        if: always()
        uses: softprops/action-gh-release@v1
        with:
          tag_name: "models_${{ env.TESTSET }}${{ env.TESTSET_TYPE }}_v1.2"
          name: "Models Test on ${{ env.TESTSET }}${{ env.TESTSET_TYPE }} data"
          files: ./*.txt
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
